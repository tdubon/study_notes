{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af6c7b15-a767-46d2-b1f5-31dd3674d1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pacific\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") #trained \n",
    "\n",
    "doc = nlp(\"Pacific ocean\") #nlp tokenizes text and creates doc object\n",
    "token = doc[0]  #select the first token Pacific \n",
    "\n",
    "print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6165b7b9-fff4-490d-94d2-0b32312fc6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Pacific\n",
      "Lemma: 7543293588541783153, Dependency: compound\n",
      "Part of Speech: NNP, Shape: Xxxxx, Entity Type: LOC\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token: {token.text}\")\n",
    "print(f\"Lemma: {token.lemma}, Dependency: {token.dep_}\")\n",
    "print(f\"Part of Speech: {token.tag_}, Shape: {token.shape_}, Entity Type: {token.ent_type_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d792102-dcc4-435e-b22b-3361dfa0cd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vector: [ 7.39085555e-01  5.25682569e-01  2.57804394e-01 -8.24920654e-01\n",
      " -9.66312289e-02  2.25829601e+00 -4.07572150e-01  4.88600016e-01\n",
      " -1.12417674e+00 -2.66576946e-01 -7.24266529e-01  5.63909829e-01\n",
      " -4.29322943e-03  3.18455517e-01 -4.00206178e-01 -7.42534757e-01\n",
      "  8.94871354e-02  6.93928957e-01  1.18385804e+00  2.33339190e+00\n",
      " -5.19754529e-01 -1.10967648e+00  2.37156451e-02  6.94226086e-01\n",
      "  3.46426904e-01 -5.54768026e-01  2.58785248e-01 -5.09009361e-01\n",
      "  1.41621363e+00 -6.01309359e-01 -8.77647251e-02  2.28351325e-01\n",
      " -6.57674134e-01  2.96291947e-01  8.46246839e-01 -1.17196918e+00\n",
      " -1.40711880e+00  1.40986252e+00 -5.13012826e-01  1.65633166e+00\n",
      " -1.25865281e-01 -8.83003950e-01  1.00630736e+00 -2.52338082e-01\n",
      " -9.54092801e-01  1.23219691e-01 -1.02663487e-02 -5.84007621e-01\n",
      "  1.21982050e+00 -3.68187338e-01  4.74482924e-01  6.45294189e-02\n",
      " -1.59020126e-01 -7.70856023e-01  3.05951953e-01  1.36112913e-01\n",
      " -5.84416151e-01 -6.22123837e-01 -8.22847784e-01 -6.19708002e-02\n",
      " -1.85400867e+00  2.03038365e-01  3.08534861e-01 -3.48681509e-01\n",
      " -5.22191465e-01 -6.24383867e-01 -1.12086713e-01 -1.04084611e+00\n",
      "  6.89242423e-01 -1.83226371e+00  1.58963352e-02  1.65608674e-02\n",
      "  1.48952007e-03  5.03540158e-01  1.38052374e-01 -1.20236123e+00\n",
      "  8.42823505e-01 -3.18001360e-01  6.34402573e-01 -7.78328001e-01\n",
      "  4.56373394e-01 -8.56016159e-01 -5.50446570e-01 -1.49848133e-01\n",
      "  5.53236842e-01 -1.81041390e-01 -1.29599124e-01 -1.21840909e-01\n",
      " -8.58333051e-01 -6.79491639e-01  8.12072337e-01  4.49918836e-01\n",
      "  7.69883752e-01  1.58755755e+00  3.02012205e-01  1.10043705e-01]\n"
     ]
    }
   ],
   "source": [
    "print(f\" Vector: {token.vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d07f46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: We\n",
      "token: failed\n",
      "token: to\n",
      "token: reject\n",
      "token: the\n",
      "token: null\n",
      "token: hypothesis\n",
      "token: with\n",
      "token: a\n",
      "token: p\n",
      "token: -\n",
      "token: value\n",
      "token: of\n",
      "token: .01\n"
     ]
    }
   ],
   "source": [
    "#Using rule based matching to capture: null hypothesis, p-value\n",
    "#import matcher\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") #trained \n",
    "\n",
    "doc = nlp(\"We failed to reject the null hypothesis with a p-value of .01\")\n",
    "\n",
    "#Printing each token\n",
    "for token in doc:\n",
    "    print(f\"token: {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59bf92a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['null hypothesis', 'p-value']\n"
     ]
    }
   ],
   "source": [
    "#initialize Matcher with shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "#create the pattern to capture instances of null hypothesis and p-value/p value\n",
    "patterns = [[{\"TEXT\": \"null\"}, {\"TEXT\": \"hypothesis\"}],[{\"TEXT\": \"p\"}, {}, {\"TEXT\": \"value\"}]]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"HYP_PATTERN\", patterns)\n",
    "\n",
    "\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502d5366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F, Ca, Mg, Na, K, Fe, Mn, Zn, Cu, Ni, Co, Cr, Cd]\n"
     ]
    }
   ],
   "source": [
    "#Using PhraseMatcher and a custom list\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This study pointed to the assessment of the chemical composition (F, Ca, Mg, Na, K, Fe, Mn, Zn, Cu, Ni,         \\\n",
    "        Co, Cr, Cd, and carbohydrate) of different marine seaweeds (red, green, and brown) from the                     \\\n",
    "        Egyptian Mediterranean Sea coast.\")\n",
    "\n",
    "metals = [\"F\", \"Ca\", \"Mg\", \"Na\", \"K\", \"Fe\", \"Mn\", \"Zn\", \"Cu\", \"Ni\", \"Co\", \"Cr\", \"Cd\"]\n",
    "\n",
    "# Initialize the PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "# Create pattern Doc objects and add them to the matcher\n",
    "#Use nlp.pipe() when processing large volumes of text\n",
    "patterns = list(nlp.pipe(metals)) \n",
    "matcher.add(\"METALS_PATTERN\", patterns)\n",
    "\n",
    "# Call the matcher on the test document and print the result\n",
    "matches = matcher(doc)\n",
    "print([doc[start:end] for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37b6dac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('F', 'Metal')]\n",
      "[('Ca', 'Metal')]\n",
      "[('Mg', 'Metal')]\n",
      "[('Na', 'Metal')]\n",
      "[('K', 'Metal')]\n",
      "[('Fe', 'Metal')]\n",
      "[('Mn', 'Metal')]\n",
      "[('Zn', 'Metal')]\n",
      "[('Cu', 'Metal')]\n",
      "[('Ni', 'Metal')]\n",
      "[('Co', 'Metal')]\n",
      "[('Cr', 'Metal')]\n",
      "[('Cd', 'Metal')]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Create a Span with the label for \"metals\"\n",
    "    span = Span(doc, start, end, label=\"Metal\")   \n",
    "\n",
    "    # Overwrite the doc.ents and add the span\n",
    "    doc.ents = [span] \n",
    "\n",
    "\n",
    "    # Get the span's root head token\n",
    "    span_root_head = span.root.head\n",
    "    # Print the text of the span root's head token and the span text\n",
    "    #print(span_root_head.text, \"-->\", span.text)\n",
    "\n",
    "    # Print the entities in the document\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents if ent.label_ == \"Metal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f7b3b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 12 F\n",
      "13 14 Ca\n",
      "15 16 Mg\n",
      "17 18 Na\n",
      "19 20 K\n",
      "21 22 Fe\n",
      "23 24 Mn\n",
      "25 26 Zn\n",
      "27 28 Cu\n",
      "29 30 Ni\n",
      "31 32 Co\n",
      "33 34 Cr\n",
      "35 36 Cd\n"
     ]
    }
   ],
   "source": [
    "#retrieve the indices (called spans) of each match in the text\n",
    "for mid, start, end in matches:\n",
    "    print(start, end, doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "323cbeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tdubon/opt/anaconda3/lib/python3.9/site-packages/spacy/displacy/__init__.py:98: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This study pointed to the assessment of the chemical composition (F, Ca, Mg, Na, K, Fe, \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cu\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", Ni, Co, Cr, Cd, and carbohydrate) of different marine seaweeds (red, green, and brown) from the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Egyptian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mediterranean Sea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " coast. The results showed that green seaweeds supplied better calcium sources than the red and brown ones. Also, red and brown seaweeds showed higher averages of Na and K than that in green species and these seaweeds could play an important role in the electrolyte balance in humans.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zn/m0vy_yh17lb67mrm0jhh0ty40000gn/T/ipykernel_3916/211834069.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cat_line.svg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/tdubon/Learning/spaCy\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"This study pointed to the assessment of the chemical composition (F, Ca, Mg, Na, K, Fe, Mn, Zn, Cu, Ni, Co, Cr, Cd, and carbohydrate) of different marine seaweeds (red, green, and brown) from the Egyptian Mediterranean Sea coast. The results showed that green seaweeds supplied better calcium sources than the red and brown ones. Also, red and brown seaweeds showed higher averages of Na and K than that in green species and these seaweeds could play an important role in the electrolyte balance in humans.\")\n",
    "\n",
    "\n",
    "displacy.serve(doc, style= \"ent\") #dep style parameter\n",
    "\n",
    "filename = \"cat_line.svg\" \n",
    "output_path = Path (\"/Users/tdubon/Learning/spaCy\" + file_name)\n",
    "output_path.open(\"w\", encoding = \"utf-8\").write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3c8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
